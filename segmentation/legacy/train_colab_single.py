"""
U-Net ãƒ—ãƒ©ãƒŠãƒªã‚¢ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ - Google Colabç‰ˆï¼ˆ1ã‚»ãƒ«å®Ÿè¡Œï¼‰

ä½¿ç”¨æ–¹æ³•:
1. Google Colabã§æ–°è¦ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’ä½œæˆ
2. ãƒ©ãƒ³ã‚¿ã‚¤ãƒ  > ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã®ã‚¿ã‚¤ãƒ—ã‚’å¤‰æ›´ > GPU (T4æ¨å¥¨) ã‚’é¸æŠ
3. ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆå…¨ä½“ã‚’1ã¤ã®ã‚»ãƒ«ã«ã‚³ãƒ”ãƒ¼&ãƒšãƒ¼ã‚¹ãƒˆ
4. ã‚»ãƒ«ã‚’å®Ÿè¡Œ
5. å­¦ç¿’å®Œäº†å¾Œã€best_unet.pth ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
"""

# ============================================================================
# ğŸ”§ è¨­å®š: ã“ã“ã‚’ç·¨é›†ã—ã¦ãã ã•ã„
# ============================================================================

# ============================================================================
# ãƒ‘ã‚¹è¨­å®š
# ============================================================================

# ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã¨ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜å ´æ‰€ï¼‰
BASE_DIR = '/content/planarian'  # ã“ã“ã‚’å¤‰æ›´ã™ã‚Œã°å…¨ä½“ã®ä¿å­˜å…ˆãŒå¤‰ã‚ã‚Šã¾ã™

# ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ã®ç›¸å¯¾ãƒ‘ã‚¹ï¼‰
DATA_DIR_NAME = 'data'           # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ«ãƒ€å
MODELS_DIR_NAME = 'models'       # ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ•ã‚©ãƒ«ãƒ€å
OUTPUTS_DIR_NAME = 'outputs'     # å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€å

# è‡ªå‹•ç”Ÿæˆã•ã‚Œã‚‹ãƒ‘ã‚¹ï¼ˆé€šå¸¸ã¯å¤‰æ›´ä¸è¦ï¼‰
DATA_DIR = f'{BASE_DIR}/{DATA_DIR_NAME}'
MODELS_DIR = f'{BASE_DIR}/{MODELS_DIR_NAME}'
OUTPUTS_DIR = f'{BASE_DIR}/{OUTPUTS_DIR_NAME}'

# ============================================================================
# ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã®è¨­å®šï¼ˆä»¥ä¸‹ã®ã„ãšã‚Œã‹ã‚’é¸æŠï¼‰
# ============================================================================

# æ–¹æ³•1: ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆæ¨å¥¨ï¼‰
USE_ZIP = True  # True: ZIPä½¿ç”¨, False: Google Driveä½¿ç”¨
ZIP_FILENAME = 'data.zip'  # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ZIPãƒ•ã‚¡ã‚¤ãƒ«å

# ZIPè§£å‡å…ˆï¼ˆé€šå¸¸ã¯å¤‰æ›´ä¸è¦ï¼‰
# ZIPã¯ BASE_DIR/DATA_DIR_NAME/ ã«è§£å‡ã•ã‚Œã¾ã™
# ZIPå†…ã« images/ ã¨ labels/ ãƒ•ã‚©ãƒ«ãƒ€ãŒå¿…è¦

# æ–¹æ³•2: Google Driveã‚’ä½¿ç”¨
# Google Driveå†…ã®ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹ã‚’æŒ‡å®šï¼ˆUSE_ZIP = False ã®å ´åˆã«ä½¿ç”¨ï¼‰
GOOGLE_DRIVE_IMAGES_DIR = '/content/drive/MyDrive/Planarian/segmentation/data/images'
GOOGLE_DRIVE_LABELS_DIR = '/content/drive/MyDrive/Planarian/segmentation/data/labels'

# ============================================================================
# å­¦ç¿’è¨­å®š
# ============================================================================
MAX_EPOCHS = 100
BATCH_SIZE = 8  # T4 GPUç”¨ï¼ˆãƒ¡ãƒ¢ãƒªä¸è¶³ã®å ´åˆã¯4ã«æ¸›ã‚‰ã™ï¼‰
LEARNING_RATE = 1e-4
EARLY_STOPPING_PATIENCE = 15
IMAGE_SIZE = 512

# ============================================================================
# ğŸ“¦ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¨ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
# ============================================================================

print("=" * 70)
print("  U-Net ãƒ—ãƒ©ãƒŠãƒªã‚¢ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ - Google Colabç‰ˆ")
print("=" * 70)
print("\n[1/6] ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­...\n")

import subprocess
import sys

# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
subprocess.check_call([sys.executable, "-m", "pip", "install", "-q",
                      "segmentation-models-pytorch", "albumentations"])

print("âœ“ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†\n")

# ============================================================================
# ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
# ============================================================================

import os
import zipfile
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, random_split
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
import albumentations as A
from albumentations.pytorch import ToTensorV2
import segmentation_models_pytorch as smp

# GPUç¢ºèª
print("[2/6] ç’°å¢ƒç¢ºèªä¸­...\n")
print(f"PyTorch version: {torch.__version__}")
print(f"CUDA available: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"CUDA version: {torch.version.cuda}")
    print(f"GPU: {torch.cuda.get_device_name(0)}")
    print(f"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
else:
    print("âš ï¸ GPUãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚CPUãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œã•ã‚Œã¾ã™ï¼ˆé…ã„ï¼‰")
print()

# ============================================================================
# ğŸ“‚ ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
# ============================================================================

print("[3/6] ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ä¸­...\n")

# ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
os.makedirs(BASE_DIR, exist_ok=True)
os.makedirs(MODELS_DIR, exist_ok=True)
os.makedirs(OUTPUTS_DIR, exist_ok=True)

print(f"ğŸ“ ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {BASE_DIR}")
print(f"   â”œâ”€ ãƒ‡ãƒ¼ã‚¿: {DATA_DIR}")
print(f"   â”œâ”€ ãƒ¢ãƒ‡ãƒ«: {MODELS_DIR}")
print(f"   â””â”€ å‡ºåŠ›: {OUTPUTS_DIR}\n")

if USE_ZIP:
    # ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    from google.colab import files
    print(f"'{ZIP_FILENAME}' ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„...")
    uploaded = files.upload()

    # è§£å‡
    for filename in uploaded.keys():
        if filename.endswith('.zip'):
            print(f"\n{filename} ã‚’è§£å‡ä¸­...")
            with zipfile.ZipFile(filename, 'r') as zip_ref:
                # DATA_DIR ã«è§£å‡
                zip_ref.extractall(DATA_DIR)
            print(f"âœ“ è§£å‡å®Œäº†: {DATA_DIR}")

    # ãƒ‘ã‚¹è¨­å®šï¼ˆZIPå†…ã®æ§‹é€ : data/images/, data/labels/ï¼‰
    IMAGES_DIR = os.path.join(DATA_DIR, 'images')
    LABELS_DIR = os.path.join(DATA_DIR, 'labels')

else:
    # Google Driveã‚’ãƒã‚¦ãƒ³ãƒˆ
    from google.colab import drive
    print("Google Driveã‚’ãƒã‚¦ãƒ³ãƒˆä¸­...")
    drive.mount('/content/drive')
    print("âœ“ ãƒã‚¦ãƒ³ãƒˆå®Œäº†")

    IMAGES_DIR = GOOGLE_DRIVE_IMAGES_DIR
    LABELS_DIR = GOOGLE_DRIVE_LABELS_DIR

# ãƒ‡ãƒ¼ã‚¿ç¢ºèª
if os.path.exists(IMAGES_DIR) and os.path.exists(LABELS_DIR):
    image_count = len([f for f in os.listdir(IMAGES_DIR) if f.endswith(('.jpg', '.png'))])
    label_count = len([f for f in os.listdir(LABELS_DIR) if f.endswith('.png')])
    print(f"\nâœ“ ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç¢ºèª:")
    print(f"  ç”»åƒãƒ•ã‚©ãƒ«ãƒ€: {IMAGES_DIR}")
    print(f"  ãƒ©ãƒ™ãƒ«ãƒ•ã‚©ãƒ«ãƒ€: {LABELS_DIR}")
    print(f"  ç”»åƒæ•°: {image_count} æš")
    print(f"  ãƒ©ãƒ™ãƒ«æ•°: {label_count} æš")

    if image_count == 0 or label_count == 0:
        raise ValueError("ç”»åƒã¾ãŸã¯ãƒ©ãƒ™ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‘ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
else:
    raise ValueError(f"ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“:\n  {IMAGES_DIR}\n  {LABELS_DIR}")

print()


# ============================================================================
# ğŸ”§ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå®šç¾©
# ============================================================================

class PlanarianDataset(Dataset):
    def __init__(self, images_dir, labels_dir, transform=None):
        self.images_dir = images_dir
        self.labels_dir = labels_dir
        self.transform = transform

        # ç”»åƒã¨ãƒ©ãƒ™ãƒ«ã®ãƒšã‚¢ã‚’å–å¾—
        self.samples = []
        for img_name in os.listdir(images_dir):
            if img_name.endswith(('.jpg', '.png')):
                img_base = os.path.splitext(img_name)[0]
                label_name = img_base + '.png'

                img_path = os.path.join(images_dir, img_name)
                label_path = os.path.join(labels_dir, label_name)

                if os.path.exists(label_path):
                    self.samples.append((img_path, label_path))

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        img_path, label_path = self.samples[idx]

        # ç”»åƒèª­ã¿è¾¼ã¿
        image = np.array(Image.open(img_path).convert('RGB'))
        mask = np.array(Image.open(label_path).convert('L'))
        mask = (mask > 127).astype(np.float32)

        # æ‹¡å¼µé©ç”¨
        if self.transform:
            augmented = self.transform(image=image, mask=mask)
            image = augmented['image']
            mask = augmented['mask']

        mask = mask.unsqueeze(0)
        return image, mask

def get_train_transform(image_size):
    return A.Compose([
        A.Resize(image_size, image_size),
        A.HorizontalFlip(p=0.5),
        A.VerticalFlip(p=0.5),
        A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5),
        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),
        A.GaussNoise(p=0.3),
        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),
        ToTensorV2()
    ])

def get_val_transform(image_size):
    return A.Compose([
        A.Resize(image_size, image_size),
        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),
        ToTensorV2()
    ])

# ============================================================================
# ğŸ§  ãƒ¢ãƒ‡ãƒ«å®šç¾©
# ============================================================================

class DiceBCELoss(nn.Module):
    def __init__(self, dice_weight=0.5, bce_weight=0.5, smooth=1e-6):
        super().__init__()
        self.dice_weight = dice_weight
        self.bce_weight = bce_weight
        self.smooth = smooth
        self.bce = nn.BCEWithLogitsLoss()

    def forward(self, pred, target):
        bce_loss = self.bce(pred, target)
        pred_sigmoid = torch.sigmoid(pred)
        pred_flat = pred_sigmoid.view(-1)
        target_flat = target.view(-1)
        intersection = (pred_flat * target_flat).sum()
        dice_loss = 1 - (2. * intersection + self.smooth) / (pred_flat.sum() + target_flat.sum() + self.smooth)
        return self.dice_weight * dice_loss + self.bce_weight * bce_loss

def dice_coefficient(pred, target, smooth=1e-6):
    pred = pred.contiguous().view(-1)
    target = target.contiguous().view(-1)
    intersection = (pred * target).sum()
    dice = (2. * intersection + smooth) / (pred.sum() + target.sum() + smooth)
    return dice

class EarlyStopping:
    def __init__(self, patience=15, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.best_score = None
        self.early_stop = False

    def __call__(self, val_loss):
        if self.best_score is None:
            self.best_score = val_loss
            return False

        if val_loss < (self.best_score - self.min_delta):
            self.best_score = val_loss
            self.counter = 0
        else:
            self.counter += 1
            if self.counter >= self.patience:
                self.early_stop = True

        return self.early_stop

# ============================================================================
# ğŸš€ ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ä½œæˆ
# ============================================================================

print("[4/6] ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’ä½œæˆä¸­...\n")

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
dataset = PlanarianDataset(IMAGES_DIR, LABELS_DIR, transform=None)
print(f"âœ“ ç·ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(dataset)}")

# Train/Valåˆ†å‰²
train_size = int(0.8 * len(dataset))
val_size = len(dataset) - train_size

generator = torch.Generator().manual_seed(42)
train_dataset, val_dataset = random_split(dataset, [train_size, val_size], generator=generator)

# Transformã‚’é©ç”¨
train_dataset.dataset.transform = get_train_transform(IMAGE_SIZE)
val_dataset.dataset.transform = get_val_transform(IMAGE_SIZE)

# DataLoaderä½œæˆ
train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)

print(f"âœ“ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿: {train_size} ã‚µãƒ³ãƒ—ãƒ«")
print(f"âœ“ æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿: {val_size} ã‚µãƒ³ãƒ—ãƒ«")
print()

# ============================================================================
# ğŸ—ï¸ ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
# ============================================================================

print("[5/6] ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ä¸­...\n")

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ãƒ‡ãƒã‚¤ã‚¹: {device}\n")

# U-Netãƒ¢ãƒ‡ãƒ«
model = smp.Unet(
    encoder_name='resnet34',
    encoder_weights='imagenet',
    in_channels=3,
    classes=1
)
model = model.to(device)

total_params = sum(p.numel() for p in model.parameters())
trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

print(f"âœ“ ãƒ¢ãƒ‡ãƒ«: U-Net (ResNet34)")
print(f"âœ“ ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {total_params:,}")
print(f"âœ“ å­¦ç¿’å¯èƒ½ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {trainable_params:,}")
print()

# æå¤±é–¢æ•°ãƒ»ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼
criterion = DiceBCELoss(dice_weight=0.5, bce_weight=0.5)
optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)
early_stopping = EarlyStopping(patience=EARLY_STOPPING_PATIENCE)

# ============================================================================
# ğŸ¯ ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ«ãƒ¼ãƒ—
# ============================================================================

print("[6/6] ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹\n")
print("=" * 70)
print(f"è¨­å®š:")
print(f"  ã‚¨ãƒãƒƒã‚¯æ•°: {MAX_EPOCHS}")
print(f"  ãƒãƒƒãƒã‚µã‚¤ã‚º: {BATCH_SIZE}")
print(f"  å­¦ç¿’ç‡: {LEARNING_RATE}")
print(f"  Early Stopping Patience: {EARLY_STOPPING_PATIENCE}")
print("=" * 70)
print()

history = {'train_loss': [], 'train_dice': [], 'val_loss': [], 'val_dice': []}
best_val_loss = float('inf')
best_model_path = os.path.join(MODELS_DIR, 'best_unet.pth')

for epoch in range(MAX_EPOCHS):
    print(f"\nEpoch {epoch + 1}/{MAX_EPOCHS}")
    print("-" * 70)

    # ============================================================================
    # Training
    # ============================================================================
    model.train()
    running_loss = 0.0
    running_dice = 0.0

    pbar = tqdm(train_loader, desc='Training')
    for images, masks in pbar:
        images = images.to(device)
        masks = masks.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, masks)
        loss.backward()
        optimizer.step()

        with torch.no_grad():
            pred_masks = torch.sigmoid(outputs)
            dice = dice_coefficient(pred_masks, masks)

        running_loss += loss.item()
        running_dice += dice.item()
        pbar.set_postfix({'loss': f'{loss.item():.4f}', 'dice': f'{dice.item():.4f}'})

    train_loss = running_loss / len(train_loader)
    train_dice = running_dice / len(train_loader)

    # ============================================================================
    # Validation
    # ============================================================================
    model.eval()
    running_loss = 0.0
    running_dice = 0.0

    with torch.no_grad():
        pbar = tqdm(val_loader, desc='Validation')
        for images, masks in pbar:
            images = images.to(device)
            masks = masks.to(device)

            outputs = model(images)
            loss = criterion(outputs, masks)

            pred_masks = torch.sigmoid(outputs)
            dice = dice_coefficient(pred_masks, masks)

            running_loss += loss.item()
            running_dice += dice.item()
            pbar.set_postfix({'loss': f'{loss.item():.4f}', 'dice': f'{dice.item():.4f}'})

    val_loss = running_loss / len(val_loader)
    val_dice = running_dice / len(val_loader)

    # å±¥æ­´ä¿å­˜
    history['train_loss'].append(train_loss)
    history['train_dice'].append(train_dice)
    history['val_loss'].append(val_loss)
    history['val_dice'].append(val_dice)

    # çµæœè¡¨ç¤º
    print(f"\nçµæœ:")
    print(f"  Train Loss: {train_loss:.4f} | Train Dice: {train_dice:.4f}")
    print(f"  Val Loss:   {val_loss:.4f} | Val Dice:   {val_dice:.4f}")

    # ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ä¿å­˜
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        torch.save({
            'epoch': epoch + 1,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'val_loss': val_loss,
            'val_dice': val_dice,
            'history': history
        }, best_model_path)
        print(f"  âœ“ ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ (Val Loss: {val_loss:.4f})")

    # Early Stopping
    if early_stopping(val_loss):
        print(f"\nâš ï¸ Early Stoppingç™ºå‹• (Epoch {epoch + 1})")
        print(f"   {EARLY_STOPPING_PATIENCE} ã‚¨ãƒãƒƒã‚¯æ”¹å–„ãªã—")
        break

# ============================================================================
# ğŸ“Š å­¦ç¿’æ›²ç·šã®ãƒ—ãƒ­ãƒƒãƒˆ
# ============================================================================

print("\n" + "=" * 70)
print("  ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†ï¼")
print("=" * 70)
print(f"Best Validation Loss: {best_val_loss:.4f}\n")

print("å­¦ç¿’æ›²ç·šã‚’ä½œæˆä¸­...")

fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Loss
axes[0].plot(history['train_loss'], label='Train Loss', linewidth=2)
axes[0].plot(history['val_loss'], label='Val Loss', linewidth=2)
axes[0].set_xlabel('Epoch', fontsize=12)
axes[0].set_ylabel('Loss', fontsize=12)
axes[0].set_title('Training & Validation Loss', fontsize=14, fontweight='bold')
axes[0].legend(fontsize=11)
axes[0].grid(True, alpha=0.3)

# Dice
axes[1].plot(history['train_dice'], label='Train Dice', linewidth=2)
axes[1].plot(history['val_dice'], label='Val Dice', linewidth=2)
axes[1].set_xlabel('Epoch', fontsize=12)
axes[1].set_ylabel('Dice Coefficient', fontsize=12)
axes[1].set_title('Training & Validation Dice', fontsize=14, fontweight='bold')
axes[1].legend(fontsize=11)
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
history_plot_path = os.path.join(OUTPUTS_DIR, 'training_history.png')
plt.savefig(history_plot_path, dpi=150, bbox_inches='tight')
print(f"âœ“ å­¦ç¿’æ›²ç·šã‚’ä¿å­˜: {history_plot_path}")
plt.show()

# ============================================================================
# ğŸ” ãƒ†ã‚¹ãƒˆæ¨è«–ï¼ˆ1æšã®ç”»åƒã§çµæœã‚’ç¢ºèªï¼‰
# ============================================================================

print("\n" + "=" * 70)
print("  ãƒ†ã‚¹ãƒˆæ¨è«–ï¼ˆã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³çµæœã®ç¢ºèªï¼‰")
print("=" * 70)

# ãƒ†ã‚¹ãƒˆç”»åƒã‚’1æšé¸æŠï¼ˆæœ€åˆã®ç”»åƒã‚’ä½¿ç”¨ï¼‰
test_image_files = [f for f in os.listdir(IMAGES_DIR) if f.endswith(('.jpg', '.png'))]
if len(test_image_files) > 0:
    test_image_name = test_image_files[0]
    test_image_path = os.path.join(IMAGES_DIR, test_image_name)
    test_label_path = os.path.join(LABELS_DIR, os.path.splitext(test_image_name)[0] + '.png')

    print(f"\nãƒ†ã‚¹ãƒˆç”»åƒ: {test_image_name}")

    # ç”»åƒèª­ã¿è¾¼ã¿
    test_image = np.array(Image.open(test_image_path).convert('RGB'))
    original_size = test_image.shape[:2]

    # ãƒ©ãƒ™ãƒ«ã‚‚èª­ã¿è¾¼ã¿ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰
    test_label = None
    if os.path.exists(test_label_path):
        test_label = np.array(Image.open(test_label_path).convert('L'))
        test_label = (test_label > 127).astype(np.uint8) * 255

    # æ¨è«–ç”¨ã«å‰å‡¦ç†
    transform = get_val_transform(IMAGE_SIZE)
    augmented = transform(image=test_image)
    input_tensor = augmented['image'].unsqueeze(0).to(device)

    # æ¨è«–å®Ÿè¡Œ
    model.eval()
    with torch.no_grad():
        output = model(input_tensor)
        pred_mask = torch.sigmoid(output).cpu().numpy()[0, 0]

    # å…ƒã®ã‚µã‚¤ã‚ºã«ãƒªã‚µã‚¤ã‚º
    pred_mask_resized = np.array(Image.fromarray((pred_mask * 255).astype(np.uint8)).resize(
        (original_size[1], original_size[0]), Image.Resampling.BILINEAR
    ))

    # äºŒå€¤åŒ–
    pred_mask_binary = (pred_mask_resized > 127).astype(np.uint8) * 255

    # é‡ã­åˆã‚ã›ç”»åƒä½œæˆï¼ˆç·‘è‰²ã§äºˆæ¸¬ãƒã‚¹ã‚¯ã‚’é‡ã­ã‚‹ï¼‰
    overlay = test_image.copy()
    overlay[pred_mask_binary > 0] = overlay[pred_mask_binary > 0] * 0.5 + np.array([0, 255, 0]) * 0.5

    # å¯è¦–åŒ–
    if test_label is not None:
        # ãƒ©ãƒ™ãƒ«ãŒã‚ã‚‹å ´åˆ: å…ƒç”»åƒãƒ»æ­£è§£ãƒ©ãƒ™ãƒ«ãƒ»äºˆæ¸¬ãƒã‚¹ã‚¯ãƒ»é‡ã­åˆã‚ã›
        fig, axes = plt.subplots(2, 2, figsize=(14, 12))

        axes[0, 0].imshow(test_image)
        axes[0, 0].set_title('Original Image', fontsize=14, fontweight='bold')
        axes[0, 0].axis('off')

        axes[0, 1].imshow(test_label, cmap='gray')
        axes[0, 1].set_title('Ground Truth Label', fontsize=14, fontweight='bold')
        axes[0, 1].axis('off')

        axes[1, 0].imshow(pred_mask_binary, cmap='gray')
        axes[1, 0].set_title('Predicted Mask', fontsize=14, fontweight='bold')
        axes[1, 0].axis('off')

        axes[1, 1].imshow(overlay)
        axes[1, 1].set_title('Overlay (Green = Prediction)', fontsize=14, fontweight='bold')
        axes[1, 1].axis('off')
    else:
        # ãƒ©ãƒ™ãƒ«ãŒãªã„å ´åˆ: å…ƒç”»åƒãƒ»äºˆæ¸¬ãƒã‚¹ã‚¯ãƒ»é‡ã­åˆã‚ã›
        fig, axes = plt.subplots(1, 3, figsize=(18, 6))

        axes[0].imshow(test_image)
        axes[0].set_title('Original Image', fontsize=14, fontweight='bold')
        axes[0].axis('off')

        axes[1].imshow(pred_mask_binary, cmap='gray')
        axes[1].set_title('Predicted Mask', fontsize=14, fontweight='bold')
        axes[1].axis('off')

        axes[2].imshow(overlay)
        axes[2].set_title('Overlay (Green = Prediction)', fontsize=14, fontweight='bold')
        axes[2].axis('off')

    plt.tight_layout()
    test_result_path = os.path.join(OUTPUTS_DIR, 'test_inference_result.png')
    plt.savefig(test_result_path, dpi=150, bbox_inches='tight')
    print(f"âœ“ ãƒ†ã‚¹ãƒˆæ¨è«–çµæœã‚’ä¿å­˜: {test_result_path}")
    plt.show()

    # çµ±è¨ˆæƒ…å ±
    pred_area = np.sum(pred_mask_binary > 0)
    total_area = pred_mask_binary.shape[0] * pred_mask_binary.shape[1]
    pred_ratio = (pred_area / total_area) * 100

    print(f"\næ¨è«–çµæœã®çµ±è¨ˆ:")
    print(f"  - ç”»åƒã‚µã‚¤ã‚º: {original_size[1]} x {original_size[0]}")
    print(f"  - æ¤œå‡ºé¢ç©: {pred_area} ãƒ”ã‚¯ã‚»ãƒ«")
    print(f"  - æ¤œå‡ºå‰²åˆ: {pred_ratio:.2f}%")

    if test_label is not None:
        label_area = np.sum(test_label > 0)
        label_ratio = (label_area / total_area) * 100

        # IoUè¨ˆç®—ï¼ˆã‚¼ãƒ­é™¤ç®—ã‚’é˜²ãï¼‰
        intersection = np.sum((pred_mask_binary > 0) & (test_label > 0))
        union = np.sum((pred_mask_binary > 0) | (test_label > 0))
        iou = intersection / union if union > 0 else 0.0

        print(f"  - æ­£è§£é¢ç©: {label_area} ãƒ”ã‚¯ã‚»ãƒ«")
        print(f"  - æ­£è§£å‰²åˆ: {label_ratio:.2f}%")
        print(f"  - IoU (Intersection over Union): {iou:.4f}")
else:
    print("\nâš ï¸ ãƒ†ã‚¹ãƒˆç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
    test_result_path = None

# ============================================================================
# ğŸ’¾ ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
# ============================================================================

print("\n" + "=" * 70)
print("  ãƒ¢ãƒ‡ãƒ«ã¨å­¦ç¿’å±¥æ­´ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
print("=" * 70)

from google.colab import files

print("\nãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
files.download(best_model_path)
files.download(history_plot_path)
if test_result_path:
    files.download(test_result_path)

print("\nâœ“ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†ï¼")
print(f"  - {os.path.basename(best_model_path)}")
print(f"  - {os.path.basename(history_plot_path)}")
if test_result_path:
    print(f"  - {os.path.basename(test_result_path)}")

print("\nğŸ“Š ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«:")
print("  âœ“ best_unet.pth - å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«")
print("  âœ“ training_history.png - å­¦ç¿’æ›²ç·šï¼ˆLoss & Diceï¼‰")
if test_result_path:
    print("  âœ“ test_inference_result.png - ãƒ†ã‚¹ãƒˆæ¨è«–çµæœï¼ˆã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç¢ºèªï¼‰")

print("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
print("  1. ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸ best_unet.pth ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã® segmentation/models/ ã«é…ç½®")
print("  2. test_inference_result.png ã§ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’ç¢ºèª")
print("  3. ãƒ­ãƒ¼ã‚«ãƒ«ã§æ¨è«–ã‚’å®Ÿè¡Œ:")
print("     cd segmentation")
print("     python inference.py --images <å…¥åŠ›> --output <å‡ºåŠ›>")
print("\n" + "=" * 70)
