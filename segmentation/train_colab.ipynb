{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# U-Net プラナリアセグメンテーション - Google Colab版\\n\",\n",
    "    \"\\n\",\n",
    "    \"## 使用方法\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. **ランタイム > ランタイムのタイプを変更 > GPU (T4推奨)** を選択\\n\",\n",
    "    \"2. すべてのセルを順番に実行\\n\",\n",
    "    \"3. 学習完了後、`best_unet.pth` をダウンロード\\n\",\n",
    "    \"4. ローカルの `segmentation/models/` に配置して推論を実行\\n\",\n",
    "    \"\\n\",\n",
    "    \"---\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. 環境セットアップ\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# GPU確認\\n\",\n",
    "    \"import torch\\n\",\n",
    "    \"print(f'PyTorch version: {torch.__version__}')\\n\",\n",
    "    \"print(f'CUDA available: {torch.cuda.is_available()}')\\n\",\n",
    "    \"if torch.cuda.is_available():\\n\",\n",
    "    \"    print(f'CUDA version: {torch.version.cuda}')\\n\",\n",
    "    \"    print(f'GPU: {torch.cuda.get_device_name(0)}')\\n\",\n",
    "    \"    print(f'VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# 必要なライブラリをインストール\\n\",\n",
    "    \"!pip install -q segmentation-models-pytorch albumentations\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. データアップロード\\n\",\n",
    "    \"\\n\",\n",
    "    \"**方法1: Google Driveから読み込む（推奨）**\\n\",\n",
    "    \"```python\\n\",\n",
    "    \"from google.colab import drive\\n\",\n",
    "    \"drive.mount('/content/drive')\\n\",\n",
    "    \"```\\n\",\n",
    "    \"\\n\",\n",
    "    \"**方法2: ZIPファイルをアップロード**\\n\",\n",
    "    \"- ローカルの `segmentation/data/` をZIP圧縮\\n\",\n",
    "    \"- Colabにアップロード\\n\",\n",
    "    \"- 解凍\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# 方法1: Google Drive マウント（推奨）\\n\",\n",
    "    \"from google.colab import drive\\n\",\n",
    "    \"drive.mount('/content/drive')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Google Driveにアップロードしたデータのパスを指定\\n\",\n",
    "    \"# 例: IMAGES_DIR = '/content/drive/MyDrive/Planarian/segmentation/data/images'\\n\",\n",
    "    \"#     LABELS_DIR = '/content/drive/MyDrive/Planarian/segmentation/data/labels'\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# 方法2: ZIPファイルアップロード\\n\",\n",
    "    \"from google.colab import files\\n\",\n",
    "    \"import zipfile\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ZIPファイルをアップロード\\n\",\n",
    "    \"print('data.zip をアップロードしてください...')\\n\",\n",
    "    \"uploaded = files.upload()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# 解凍\\n\",\n",
    "    \"for filename in uploaded.keys():\\n\",\n",
    "    \"    if filename.endswith('.zip'):\\n\",\n",
    "    \"        with zipfile.ZipFile(filename, 'r') as zip_ref:\\n\",\n",
    "    \"            zip_ref.extractall('/content/data')\\n\",\n",
    "    \"        print(f'{filename} を解凍しました')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# パス設定\\n\",\n",
    "    \"IMAGES_DIR = '/content/data/images'\\n\",\n",
    "    \"LABELS_DIR = '/content/data/labels'\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. 設定ファイル（config.py）\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"%%writefile config.py\\n\",\n",
    "    \"\\\"\\\"\\\"\\n\",\n",
    "    \"セグメンテーションシステムの設定ファイル - Google Colab版\\n\",\n",
    "    \"\\\"\\\"\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"\\n\",\n",
    "    \"# パス設定（Colab用）\\n\",\n",
    "    \"BASE_DIR = '/content'\\n\",\n",
    "    \"MODELS_DIR = os.path.join(BASE_DIR, 'models')\\n\",\n",
    "    \"OUTPUTS_DIR = os.path.join(BASE_DIR, 'outputs')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# データパス（後で設定）\\n\",\n",
    "    \"IMAGES_DIR = None\\n\",\n",
    "    \"LABELS_DIR = None\\n\",\n",
    "    \"\\n\",\n",
    "    \"# モデル保存パス\\n\",\n",
    "    \"BEST_MODEL_PATH = os.path.join(MODELS_DIR, 'best_unet.pth')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# モデル設定\\n\",\n",
    "    \"IMAGE_HEIGHT = 512\\n\",\n",
    "    \"IMAGE_WIDTH = 512\\n\",\n",
    "    \"ENCODER_NAME = 'resnet34'\\n\",\n",
    "    \"ENCODER_WEIGHTS = 'imagenet'\\n\",\n",
    "    \"IN_CHANNELS = 3\\n\",\n",
    "    \"OUT_CHANNELS = 1\\n\",\n",
    "    \"\\n\",\n",
    "    \"# 学習設定（GPU用）\\n\",\n",
    "    \"DEVICE = 'cuda'\\n\",\n",
    "    \"BATCH_SIZE = 8  # T4 GPU用（15GB VRAM）\\n\",\n",
    "    \"NUM_WORKERS = 2\\n\",\n",
    "    \"LEARNING_RATE = 1e-4\\n\",\n",
    "    \"WEIGHT_DECAY = 1e-5\\n\",\n",
    "    \"MAX_EPOCHS = 100\\n\",\n",
    "    \"EARLY_STOPPING_PATIENCE = 15\\n\",\n",
    "    \"TRAIN_VAL_SPLIT = 0.8\\n\",\n",
    "    \"RANDOM_SEED = 42\\n\",\n",
    "    \"\\n\",\n",
    "    \"# 損失関数の重み\\n\",\n",
    "    \"DICE_WEIGHT = 0.5\\n\",\n",
    "    \"BCE_WEIGHT = 0.5\\n\",\n",
    "    \"\\n\",\n",
    "    \"# データ拡張設定\\n\",\n",
    "    \"AUGMENTATION_PROB = 0.5\\n\",\n",
    "    \"BRIGHTNESS_LIMIT = 0.2\\n\",\n",
    "    \"CONTRAST_LIMIT = 0.2\\n\",\n",
    "    \"ROTATE_LIMIT = 15\\n\",\n",
    "    \"GAUSSIAN_NOISE_VAR = (10.0, 50.0)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. ユーティリティ関数（utils.py）\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"%%writefile utils.py\\n\",\n",
    "    \"\\\"\\\"\\\"\\n\",\n",
    "    \"ユーティリティ関数\\n\",\n",
    "    \"\\\"\\\"\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"import torch\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"from datetime import datetime\\n\",\n",
    "    \"\\n\",\n",
    "    \"def create_dirs_if_not_exist(dirs):\\n\",\n",
    "    \"    \\\"\\\"\\\"ディレクトリ作成\\\"\\\"\\\"\\n\",\n",
    "    \"    for d in dirs:\\n\",\n",
    "    \"        os.makedirs(d, exist_ok=True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"def timestamp():\\n\",\n",
    "    \"    \\\"\\\"\\\"タイムスタンプ\\\"\\\"\\\"\\n\",\n",
    "    \"    return datetime.now().strftime('%Y-%m-%d %H:%M:%S')\\n\",\n",
    "    \"\\n\",\n",
    "    \"def dice_coefficient(pred, target, smooth=1e-6):\\n\",\n",
    "    \"    \\\"\\\"\\\"Dice係数\\\"\\\"\\\"\\n\",\n",
    "    \"    pred = pred.contiguous().view(-1)\\n\",\n",
    "    \"    target = target.contiguous().view(-1)\\n\",\n",
    "    \"    intersection = (pred * target).sum()\\n\",\n",
    "    \"    dice = (2. * intersection + smooth) / (pred.sum() + target.sum() + smooth)\\n\",\n",
    "    \"    return dice\\n\",\n",
    "    \"\\n\",\n",
    "    \"def plot_training_history(history, save_path):\\n\",\n",
    "    \"    \\\"\\\"\\\"学習曲線プロット\\\"\\\"\\\"\\n\",\n",
    "    \"    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Loss\\n\",\n",
    "    \"    axes[0].plot(history['train_loss'], label='Train Loss', linewidth=2)\\n\",\n",
    "    \"    axes[0].plot(history['val_loss'], label='Val Loss', linewidth=2)\\n\",\n",
    "    \"    axes[0].set_xlabel('Epoch', fontsize=12)\\n\",\n",
    "    \"    axes[0].set_ylabel('Loss', fontsize=12)\\n\",\n",
    "    \"    axes[0].set_title('Training & Validation Loss', fontsize=14, fontweight='bold')\\n\",\n",
    "    \"    axes[0].legend(fontsize=11)\\n\",\n",
    "    \"    axes[0].grid(True, alpha=0.3)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Dice\\n\",\n",
    "    \"    axes[1].plot(history['train_dice'], label='Train Dice', linewidth=2)\\n\",\n",
    "    \"    axes[1].plot(history['val_dice'], label='Val Dice', linewidth=2)\\n\",\n",
    "    \"    axes[1].set_xlabel('Epoch', fontsize=12)\\n\",\n",
    "    \"    axes[1].set_ylabel('Dice Coefficient', fontsize=12)\\n\",\n",
    "    \"    axes[1].set_title('Training & Validation Dice', fontsize=14, fontweight='bold')\\n\",\n",
    "    \"    axes[1].legend(fontsize=11)\\n\",\n",
    "    \"    axes[1].grid(True, alpha=0.3)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.savefig(save_path, dpi=150, bbox_inches='tight')\\n\",\n",
    "    \"    print(f\\\"学習曲線を保存しました: {save_path}\\\")\\n\",\n",
    "    \"    plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. データセット（dataset.py）\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"%%writefile dataset.py\\n\",\n",
    "    \"\\\"\\\"\\\"\\n\",\n",
    "    \"データセット定義\\n\",\n",
    "    \"\\\"\\\"\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"import torch\\n\",\n",
    "    \"from torch.utils.data import Dataset, DataLoader, random_split\\n\",\n",
    "    \"from PIL import Image\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import albumentations as A\\n\",\n",
    "    \"from albumentations.pytorch import ToTensorV2\\n\",\n",
    "    \"import config\\n\",\n",
    "    \"\\n\",\n",
    "    \"class PlanarianDataset(Dataset):\\n\",\n",
    "    \"    def __init__(self, images_dir, labels_dir, transform=None):\\n\",\n",
    "    \"        self.images_dir = images_dir\\n\",\n",
    "    \"        self.labels_dir = labels_dir\\n\",\n",
    "    \"        self.transform = transform\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # 画像とラベルのペアを取得\\n\",\n",
    "    \"        self.samples = []\\n\",\n",
    "    \"        for img_name in os.listdir(images_dir):\\n\",\n",
    "    \"            if img_name.endswith(('.jpg', '.png')):\\n\",\n",
    "    \"                img_base = os.path.splitext(img_name)[0]\\n\",\n",
    "    \"                label_name = img_base + '.png'\\n\",\n",
    "    \"                \\n\",\n",
    "    \"                img_path = os.path.join(images_dir, img_name)\\n\",\n",
    "    \"                label_path = os.path.join(labels_dir, label_name)\\n\",\n",
    "    \"                \\n\",\n",
    "    \"                if os.path.exists(label_path):\\n\",\n",
    "    \"                    self.samples.append((img_path, label_path))\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        print(f\\\"データセットを構築しました:\\\")\\n\",\n",
    "    \"        print(f\\\"  - 画像ディレクトリ: {images_dir}\\\")\\n\",\n",
    "    \"        print(f\\\"  - ラベルディレクトリ: {labels_dir}\\\")\\n\",\n",
    "    \"        print(f\\\"  - 有効なサンプル数: {len(self.samples)}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    def __len__(self):\\n\",\n",
    "    \"        return len(self.samples)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    def __getitem__(self, idx):\\n\",\n",
    "    \"        img_path, label_path = self.samples[idx]\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # 画像読み込み\\n\",\n",
    "    \"        image = np.array(Image.open(img_path).convert('RGB'))\\n\",\n",
    "    \"        mask = np.array(Image.open(label_path).convert('L'))\\n\",\n",
    "    \"        mask = (mask > 127).astype(np.float32)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # 拡張適用\\n\",\n",
    "    \"        if self.transform:\\n\",\n",
    "    \"            augmented = self.transform(image=image, mask=mask)\\n\",\n",
    "    \"            image = augmented['image']\\n\",\n",
    "    \"            mask = augmented['mask']\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        mask = mask.unsqueeze(0)\\n\",\n",
    "    \"        return image, mask\\n\",\n",
    "    \"\\n\",\n",
    "    \"def get_train_transform():\\n\",\n",
    "    \"    return A.Compose([\\n\",\n",
    "    \"        A.Resize(config.IMAGE_HEIGHT, config.IMAGE_WIDTH),\\n\",\n",
    "    \"        A.HorizontalFlip(p=0.5),\\n\",\n",
    "    \"        A.VerticalFlip(p=0.5),\\n\",\n",
    "    \"        A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=config.ROTATE_LIMIT, p=0.5),\\n\",\n",
    "    \"        A.RandomBrightnessContrast(brightness_limit=config.BRIGHTNESS_LIMIT, contrast_limit=config.CONTRAST_LIMIT, p=0.5),\\n\",\n",
    "    \"        A.GaussNoise(p=0.3),\\n\",\n",
    "    \"        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\\n\",\n",
    "    \"        ToTensorV2()\\n\",\n",
    "    \"    ])\\n\",\n",
    "    \"\\n\",\n",
    "    \"def get_val_transform():\\n\",\n",
    "    \"    return A.Compose([\\n\",\n",
    "    \"        A.Resize(config.IMAGE_HEIGHT, config.IMAGE_WIDTH),\\n\",\n",
    "    \"        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\\n\",\n",
    "    \"        ToTensorV2()\\n\",\n",
    "    \"    ])\\n\",\n",
    "    \"\\n\",\n",
    "    \"def create_dataloaders(images_dir, labels_dir, batch_size, num_workers, train_val_split, random_seed):\\n\",\n",
    "    \"    dataset = PlanarianDataset(images_dir, labels_dir, transform=None)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Train/Val分割\\n\",\n",
    "    \"    train_size = int(train_val_split * len(dataset))\\n\",\n",
    "    \"    val_size = len(dataset) - train_size\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    generator = torch.Generator().manual_seed(random_seed)\\n\",\n",
    "    \"    train_dataset, val_dataset = random_split(dataset, [train_size, val_size], generator=generator)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Transformを適用\\n\",\n",
    "    \"    train_dataset.dataset.transform = get_train_transform()\\n\",\n",
    "    \"    val_dataset.dataset.transform = get_val_transform()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\\n\",\n",
    "    \"    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"データ分割:\\\")\\n\",\n",
    "    \"    print(f\\\"  - 学習データ: {train_size} サンプル\\\")\\n\",\n",
    "    \"    print(f\\\"  - 検証データ: {val_size} サンプル\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return train_loader, val_loader\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. モデル定義（unet_model.py）\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"%%writefile unet_model.py\\n\",\n",
    "    \"\\\"\\\"\\\"\\n\",\n",
    "    \"U-Netモデル定義\\n\",\n",
    "    \"\\\"\\\"\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"import torch\\n\",\n",
    "    \"import torch.nn as nn\\n\",\n",
    "    \"import segmentation_models_pytorch as smp\\n\",\n",
    "    \"\\n\",\n",
    "    \"class DiceBCELoss(nn.Module):\\n\",\n",
    "    \"    def __init__(self, dice_weight=0.5, bce_weight=0.5, smooth=1e-6):\\n\",\n",
    "    \"        super().__init__()\\n\",\n",
    "    \"        self.dice_weight = dice_weight\\n\",\n",
    "    \"        self.bce_weight = bce_weight\\n\",\n",
    "    \"        self.smooth = smooth\\n\",\n",
    "    \"        self.bce = nn.BCEWithLogitsLoss()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    def forward(self, pred, target):\\n\",\n",
    "    \"        bce_loss = self.bce(pred, target)\\n\",\n",
    "    \"        pred_sigmoid = torch.sigmoid(pred)\\n\",\n",
    "    \"        pred_flat = pred_sigmoid.view(-1)\\n\",\n",
    "    \"        target_flat = target.view(-1)\\n\",\n",
    "    \"        intersection = (pred_flat * target_flat).sum()\\n\",\n",
    "    \"        dice_loss = 1 - (2. * intersection + self.smooth) / (pred_flat.sum() + target_flat.sum() + self.smooth)\\n\",\n",
    "    \"        return self.dice_weight * dice_loss + self.bce_weight * bce_loss\\n\",\n",
    "    \"\\n\",\n",
    "    \"def build_model(encoder_name, encoder_weights, in_channels, out_channels, device):\\n\",\n",
    "    \"    model = smp.Unet(\\n\",\n",
    "    \"        encoder_name=encoder_name,\\n\",\n",
    "    \"        encoder_weights=encoder_weights,\\n\",\n",
    "    \"        in_channels=in_channels,\\n\",\n",
    "    \"        classes=out_channels\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    model = model.to(device)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    total_params = sum(p.numel() for p in model.parameters())\\n\",\n",
    "    \"    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"モデルを構築しました:\\\")\\n\",\n",
    "    \"    print(f\\\"  - エンコーダー: {encoder_name}\\\")\\n\",\n",
    "    \"    print(f\\\"  - 事前学習済み重み: {encoder_weights}\\\")\\n\",\n",
    "    \"    print(f\\\"  - 総パラメータ数: {total_params:,}\\\")\\n\",\n",
    "    \"    print(f\\\"  - 学習可能パラメータ数: {trainable_params:,}\\\")\\n\",\n",
    "    \"    print(f\\\"  - デバイス: {device}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return model\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 7. トレーニングコード\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import torch\\n\",\n",
    "    \"import torch.optim as optim\\n\",\n",
    "    \"from tqdm import tqdm\\n\",\n",
    "    \"import config\\n\",\n",
    "    \"from utils import create_dirs_if_not_exist, plot_training_history, dice_coefficient, timestamp\\n\",\n",
    "    \"from unet_model import build_model, DiceBCELoss\\n\",\n",
    "    \"from dataset import create_dataloaders\\n\",\n",
    "    \"\\n\",\n",
    "    \"class EarlyStopping:\\n\",\n",
    "    \"    def __init__(self, patience=15, min_delta=0, mode='min'):\\n\",\n",
    "    \"        self.patience = patience\\n\",\n",
    "    \"        self.min_delta = min_delta\\n\",\n",
    "    \"        self.mode = mode\\n\",\n",
    "    \"        self.counter = 0\\n\",\n",
    "    \"        self.best_score = None\\n\",\n",
    "    \"        self.early_stop = False\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    def __call__(self, score):\\n\",\n",
    "    \"        if self.best_score is None:\\n\",\n",
    "    \"            self.best_score = score\\n\",\n",
    "    \"            return False\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        if self.mode == 'min':\\n\",\n",
    "    \"            improved = score < (self.best_score - self.min_delta)\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            improved = score > (self.best_score + self.min_delta)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        if improved:\\n\",\n",
    "    \"            self.best_score = score\\n\",\n",
    "    \"            self.counter = 0\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            self.counter += 1\\n\",\n",
    "    \"            if self.counter >= self.patience:\\n\",\n",
    "    \"                self.early_stop = True\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        return self.early_stop\\n\",\n",
    "    \"\\n\",\n",
    "    \"def train_one_epoch(model, dataloader, criterion, optimizer, device):\\n\",\n",
    "    \"    model.train()\\n\",\n",
    "    \"    running_loss = 0.0\\n\",\n",
    "    \"    running_dice = 0.0\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    pbar = tqdm(dataloader, desc='Training')\\n\",\n",
    "    \"    for images, masks in pbar:\\n\",\n",
    "    \"        images = images.to(device)\\n\",\n",
    "    \"        masks = masks.to(device)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        optimizer.zero_grad()\\n\",\n",
    "    \"        outputs = model(images)\\n\",\n",
    "    \"        loss = criterion(outputs, masks)\\n\",\n",
    "    \"        loss.backward()\\n\",\n",
    "    \"        optimizer.step()\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        with torch.no_grad():\\n\",\n",
    "    \"            pred_masks = torch.sigmoid(outputs)\\n\",\n",
    "    \"            dice = dice_coefficient(pred_masks, masks)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        running_loss += loss.item()\\n\",\n",
    "    \"        running_dice += dice.item()\\n\",\n",
    "    \"        pbar.set_postfix({'loss': loss.item(), 'dice': dice.item()})\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    epoch_loss = running_loss / len(dataloader)\\n\",\n",
    "    \"    epoch_dice = running_dice / len(dataloader)\\n\",\n",
    "    \"    return epoch_loss, epoch_dice\\n\",\n",
    "    \"\\n\",\n",
    "    \"def validate(model, dataloader, criterion, device):\\n\",\n",
    "    \"    model.eval()\\n\",\n",
    "    \"    running_loss = 0.0\\n\",\n",
    "    \"    running_dice = 0.0\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    with torch.no_grad():\\n\",\n",
    "    \"        pbar = tqdm(dataloader, desc='Validation')\\n\",\n",
    "    \"        for images, masks in pbar:\\n\",\n",
    "    \"            images = images.to(device)\\n\",\n",
    "    \"            masks = masks.to(device)\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            outputs = model(images)\\n\",\n",
    "    \"            loss = criterion(outputs, masks)\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            pred_masks = torch.sigmoid(outputs)\\n\",\n",
    "    \"            dice = dice_coefficient(pred_masks, masks)\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            running_loss += loss.item()\\n\",\n",
    "    \"            running_dice += dice.item()\\n\",\n",
    "    \"            pbar.set_postfix({'loss': loss.item(), 'dice': dice.item()})\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    epoch_loss = running_loss / len(dataloader)\\n\",\n",
    "    \"    epoch_dice = running_dice / len(dataloader)\\n\",\n",
    "    \"    return epoch_loss, epoch_dice\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 8. データパス設定\\n\",\n",
    "    \"\\n\",\n",
    "    \"**Google Driveを使用する場合**または**ZIPアップロード後**、ここでパスを設定してください。\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# データパスを設定（自分の環境に合わせて変更）\\n\",\n",
    "    \"\\n\",\n",
    "    \"# 例1: Google Driveから\\n\",\n",
    "    \"# IMAGES_DIR = '/content/drive/MyDrive/Planarian/segmentation/data/images'\\n\",\n",
    "    \"# LABELS_DIR = '/content/drive/MyDrive/Planarian/segmentation/data/labels'\\n\",\n",
    "    \"\\n\",\n",
    "    \"# 例2: ZIPアップロード後\\n\",\n",
    "    \"IMAGES_DIR = '/content/data/images'\\n\",\n",
    "    \"LABELS_DIR = '/content/data/labels'\\n\",\n",
    "    \"\\n\",\n",
    "    \"# configに設定\\n\",\n",
    "    \"config.IMAGES_DIR = IMAGES_DIR\\n\",\n",
    "    \"config.LABELS_DIR = LABELS_DIR\\n\",\n",
    "    \"\\n\",\n",
    "    \"# データ確認\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"print(f\\\"画像数: {len([f for f in os.listdir(IMAGES_DIR) if f.endswith(('.jpg', '.png'))])}\\\")\\n\",\n",
    "    \"print(f\\\"ラベル数: {len([f for f in os.listdir(LABELS_DIR) if f.endswith('.png')])}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 9. トレーニング実行\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# トレーニング開始\\n\",\n",
    "    \"print(f\\\"\\\\n{'='*60}\\\")\\n\",\n",
    "    \"print(f\\\"  U-Net学習開始\\\")\\n\",\n",
    "    \"print(f\\\"{'='*60}\\\\n\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ディレクトリ作成\\n\",\n",
    "    \"create_dirs_if_not_exist([config.MODELS_DIR, config.OUTPUTS_DIR])\\n\",\n",
    "    \"\\n\",\n",
    "    \"# デバイス確認\\n\",\n",
    "    \"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\\n\",\n",
    "    \"print(f\\\"デバイス: {device}\\\")\\n\",\n",
    "    \"if device.type == 'cuda':\\n\",\n",
    "    \"    print(f\\\"GPU: {torch.cuda.get_device_name(0)}\\\")\\n\",\n",
    "    \"    print(f\\\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\\\\n\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# データローダー\\n\",\n",
    "    \"train_loader, val_loader = create_dataloaders(\\n\",\n",
    "    \"    images_dir=IMAGES_DIR,\\n\",\n",
    "    \"    labels_dir=LABELS_DIR,\\n\",\n",
    "    \"    batch_size=config.BATCH_SIZE,\\n\",\n",
    "    \"    num_workers=config.NUM_WORKERS,\\n\",\n",
    "    \"    train_val_split=config.TRAIN_VAL_SPLIT,\\n\",\n",
    "    \"    random_seed=config.RANDOM_SEED\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# モデル構築\\n\",\n",
    "    \"model = build_model(\\n\",\n",
    "    \"    encoder_name=config.ENCODER_NAME,\\n\",\n",
    "    \"    encoder_weights=config.ENCODER_WEIGHTS,\\n\",\n",
    "    \"    in_channels=config.IN_CHANNELS,\\n\",\n",
    "    \"    out_channels=config.OUT_CHANNELS,\\n\",\n",
    "    \"    device=device\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# 損失関数・オプティマイザー\\n\",\n",
    "    \"criterion = DiceBCELoss(dice_weight=config.DICE_WEIGHT, bce_weight=config.BCE_WEIGHT)\\n\",\n",
    "    \"optimizer = optim.Adam(model.parameters(), lr=config.LEARNING_RATE, weight_decay=config.WEIGHT_DECAY)\\n\",\n",
    "    \"early_stopping = EarlyStopping(patience=config.EARLY_STOPPING_PATIENCE, mode='min')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# 学習履歴\\n\",\n",
    "    \"history = {'train_loss': [], 'train_dice': [], 'val_loss': [], 'val_dice': []}\\n\",\n",
    "    \"best_val_loss = float('inf')\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\n学習開始\\\\n\\\")\\n\",\n",
    "    \"print(f\\\"{'='*60}\\\")\\n\",\n",
    "    \"print(f\\\"設定:\\\")\\n\",\n",
    "    \"print(f\\\"  - エポック数: {config.MAX_EPOCHS}\\\")\\n\",\n",
    "    \"print(f\\\"  - バッチサイズ: {config.BATCH_SIZE}\\\")\\n\",\n",
    "    \"print(f\\\"  - 学習率: {config.LEARNING_RATE}\\\")\\n\",\n",
    "    \"print(f\\\"{'='*60}\\\\n\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# 学習ループ\\n\",\n",
    "    \"for epoch in range(config.MAX_EPOCHS):\\n\",\n",
    "    \"    print(f\\\"\\\\nEpoch {epoch + 1}/{config.MAX_EPOCHS}\\\")\\n\",\n",
    "    \"    print(f\\\"{'-'*60}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    train_loss, train_dice = train_one_epoch(model, train_loader, criterion, optimizer, device)\\n\",\n",
    "    \"    val_loss, val_dice = validate(model, val_loader, criterion, device)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    history['train_loss'].append(train_loss)\\n\",\n",
    "    \"    history['train_dice'].append(train_dice)\\n\",\n",
    "    \"    history['val_loss'].append(val_loss)\\n\",\n",
    "    \"    history['val_dice'].append(val_dice)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"\\\\n結果:\\\")\\n\",\n",
    "    \"    print(f\\\"  Train Loss: {train_loss:.4f} | Train Dice: {train_dice:.4f}\\\")\\n\",\n",
    "    \"    print(f\\\"  Val Loss:   {val_loss:.4f} | Val Dice:   {val_dice:.4f}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if val_loss < best_val_loss:\\n\",\n",
    "    \"        best_val_loss = val_loss\\n\",\n",
    "    \"        torch.save({\\n\",\n",
    "    \"            'epoch': epoch + 1,\\n\",\n",
    "    \"            'model_state_dict': model.state_dict(),\\n\",\n",
    "    \"            'optimizer_state_dict': optimizer.state_dict(),\\n\",\n",
    "    \"            'val_loss': val_loss,\\n\",\n",
    "    \"            'val_dice': val_dice,\\n\",\n",
    "    \"            'history': history\\n\",\n",
    "    \"        }, config.BEST_MODEL_PATH)\\n\",\n",
    "    \"        print(f\\\"  ✓ ベストモデルを保存しました\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if early_stopping(val_loss):\\n\",\n",
    "    \"        print(f\\\"\\\\nEarly Stopping発動 (Epoch {epoch + 1})\\\")\\n\",\n",
    "    \"        break\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\n{'='*60}\\\")\\n\",\n",
    "    \"print(f\\\"  学習完了\\\")\\n\",\n",
    "    \"print(f\\\"{'='*60}\\\")\\n\",\n",
    "    \"print(f\\\"Best Val Loss: {best_val_loss:.4f}\\\\n\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# 学習曲線プロット\\n\",\n",
    "    \"plot_path = os.path.join(config.OUTPUTS_DIR, 'training_history.png')\\n\",\n",
    "    \"plot_training_history(history, plot_path)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 10. モデルのダウンロード\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# モデルと学習曲線をダウンロード\\n\",\n",
    "    \"from google.colab import files\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"モデルと学習履歴をダウンロードします...\\\")\\n\",\n",
    "    \"files.download(config.BEST_MODEL_PATH)\\n\",\n",
    "    \"files.download(os.path.join(config.OUTPUTS_DIR, 'training_history.png'))\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nダウンロード完了！\\\")\\n\",\n",
    "    \"print(\\\"ローカルの segmentation/models/ に best_unet.pth を配置してください\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"---\\n\",\n",
    "    \"\\n\",\n",
    "    \"## 次のステップ\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. `best_unet.pth` をダウンロード\\n\",\n",
    "    \"2. ローカルの `segmentation/models/best_unet.pth` に配置\\n\",\n",
    "    \"3. ローカルで推論を実行:\\n\",\n",
    "    \"   ```powershell\\n\",\n",
    "    \"   cd segmentation\\n\",\n",
    "    \"   python inference.py --images <入力> --output <出力>\\n\",\n",
    "    \"   ```\\n\",\n",
    "    \"\\n\",\n",
    "    \"---\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"accelerator\": \"GPU\",\n",
    "  \"colab\": {\n",
    "   \"gpuType\": \"T4\",\n",
    "   \"provenance\": []\n",
    "  },\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"name\": \"python\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 0\n",
    "}\n"
   ],
   "id": "3912d20af9643d1f"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
